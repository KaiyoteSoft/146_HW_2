---
title: "Homework 2"
author: "Kai Oda"
date: "1/25/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F)
knitr::opts_knit$set("~/Biology/146/Homework_2")

# Include your libraries here
# Do not include lines used to install packages

library(ggplot2)
library(ggridges)
library(car)
library(abd)
library(dplyr)
library(tidyverse)
```
### Objectives
In this homework assignment, you will:

1. Apply your plotting skills to visualize data before analysis
2. Decide on an appropriate t-test and formulate statistical hypotheses
3. Conduct t-tests and generate confidence intervals
4. Interpret results
5. Investigate the robustness of the two sample test using Type I errors
6. Understand statistical power and Type II errors

### Q1: Flycatcher patches (22 pts)

#### (a. 1pt) Load the FlycatcherPatch dataset from the abd package and read the corresponding information in the help tab. Show the first six lines of the data.

```{r}
FlycatcherPatch_data <- FlycatcherPatch
FlycatcherPatch_data2 <- FlycatcherPatch
names(FlycatcherPatch_data) = c("c", "void")
names(FlycatcherPatch_data2) = c("void", "c")

empty <- data.frame(year = c(rep("Year",60)), allData=c(rep("", 60)), stringsAsFactors = FALSE)
empty <- rbind(FlycatcherPatch_data, FlycatcherPatch_data2)
str(empty)
empty$year[1:30] <- c("Year_1")
empty$year[31:60] <- c("Year_2")

# ?FlycatcherPatch
head(FlycatcherPatch)
```


#### (b. 5pts) Create an appropriate plot to visualize the data. Write one or two sentences describing the data.

```{r}

# Your plot here
ggplot(empty, aes(x=year, y=c))+
  geom_boxplot(aes(fill=year))+
  ggtitle("Forehead Patch Size in Collared Flycatchers over two years")+
  labs(x="Year", y="Forehead patch size (unknown units)")
```

In year two flycatcher patch size had a slightly higher median and was less variable compared to year one. However, it is difficult to tell if there was a significant difference in patch size between the two years. 

#### (c. 2pts) Write the null and alternative hypotheses for a paired t-test for this dataset.

Null Hypothesis: There is no difference in the mean of the differences (the mean of the differences is equal to zero) between year one and year two. <br />
Alternative hypothesis: There is a difference in the mean of differences between year one and year two. 

#### (d. 3pts) Conduct a paired t-test by first calculating the values needed to calculate the t value:
(Hint: You will need to create a column of differences)

```{r}

# Replace "NULL" with the appropriate code
FlycatcherPatch$diff <- FlycatcherPatch$patch98 - FlycatcherPatch$patch99
mean_diff = mean(FlycatcherPatch$diff)
sd_diff = sd(FlycatcherPatch$diff)
se_diff = sd_diff/sqrt(length(FlycatcherPatch$diff))
```
The mean difference is `r mean_diff`, the standard deviation is `r sd_diff`, and the standard error of the mean is `r se_diff`.


#### (e. 2pts) Now calculate the t value and find the critical t value using the appropriate R function ($\frac{\alpha}{2}$=0.025)

```{r}

tval = (mean_diff - 0)/ (sd_diff/sqrt(length(FlycatcherPatch$diff)))
t_star = qt(1-0.025, 29)

```
The t-value is `1.497` and t* is `2.045`.

#### (f. 1pt) What is your *two-sided* p-value?

```{r}

pval= 0.145


```

My p-value is `0.145`.


#### (g. 2pts) Conduct a paired test using the t.test function and compare to your calculations. Interpret the results of these tests by explaining whether or not you reject the null hypothesis.

```{r}

# Test code here
tval = t.test(FlycatcherPatch$diff)
t_star = qt(1-0.025, 29)
```

We cannot reject the null hypothesis that there is a difference in the forehead patch size of collared flycatchers between the two years. Since our calculated tval is less than the critical t_star value we cannot reject the null hypothesis (that there is no difference between the two years). 

#### (h. 2pts) What would be the null and alternative hypotheses for a two sample test?

Null hypothesis - There is no significant difference between the mean of forehead patches collected during the first year and the mean of the second year. <br />
Alternative hypothesis - There is a significant difference in the mean of forehead patches collected between the two years. 


#### (i. 2pts) Conduct a two-sample t-test using the t.test function and assuming equal variances. State your conclusions in terms of the null hypothesis. 

```{r}

two_tval <- t.test(FlycatcherPatch$patch98, FlycatcherPatch$patch99, var.equal=TRUE)

```

Because the p value is greater than 0.05 we cannot reject the null hypothesis that there is no significant difference between the two years. 

#### (j. 2pts) Explain the difference between a paired and two-sample test and which one is more appropriate for this dataset.

A paired t-test is used to compare the mean of the difference between non-independent subjects. In short, the paired t-test is a one sample t test on the difference between two samples. 
A two-sample test is used to used to compare the difference of the means of two independent samples. 

A paired t-test is most appropriate for this dataset, because the two samples have the same conditions for everything except the variable we are testing for — the difference in forehead patch across two separate years. Otherwise, the environment, sex and population size are all the same between the two populations. 


### Q2: Dominant hand vs/ weak hand dexterity  (18 pts)
  
#### Use the file with your dexterity results for this problem.
https://docs.google.com/spreadsheets/d/1SrhY3qzY3fk_quT9HiRbT7kPuaWHUQEXMCycmmeihwg/edit#gid=0
  
#### Use a paired t-test to answer the following question:  *Does writing the phrase take a different amount of time with your weak v. dominant hand?* 
  
  
#### (a. 2pts) Clearly state your null and alternative hypotheses of your paired t-test. 

Null hypothesis - There is no difference in writing time between one's weak vs. dominant hand. 
Alternative hypothesis - Using one's weak vs. dominant hand has a significant effect on writing time. 


#### (b. 3pts) Visualize your data in a meaningful way and describe what you are showing.


```{r}
dexterity <- read.csv("Dexterity_Data.csv")
dexterity$X <- NULL
dexterity$Name <- NULL
dexterity$Handedness <- NULL
# Plot code
dexterity_data <- dexterity %>%
  gather(key=Hand, Time, 1:2)

# gather(dexterity, "Hand", "Time", 1:2)

ggplot(dexterity_data, aes(x=Hand, y=Time))+
  geom_boxplot(aes(fill=Hand))+
  labs(x="Handedness", y="Time (sec)")+
  ggtitle("Writing times using dominant vs. weak hands")


```

This graph shows that writing time is shorter when one uses their dominant hand compared to their weak hand. Additionally, the range of times that it takes to write with one's weak hand is greater when compared to the range of dominant hands. 


#### (c. 3pts) Determine if the data are normally distributed and, if not, whether you think the Central Limit Theorem will allow you to use a statistical test that assumes normality. Include both a Q-Qplot and a Shapiro Wilk statistic.

  
```{r}

# Assumption testing code here
qqPlot(dexterity$Weak)
shapiro.test(dexterity$Weak)

qqPlot(dexterity$Dominant)
shapiro.test(dexterity$Dominant)

mean_sample_weak = NULL 
for (i in 1:10) {
  temp_sample_weak <- sample(dexterity$Weak, 10)
  mean_temp_weak <- mean(temp_sample_weak)
  mean_sample_weak <- c(mean_sample_weak, mean_temp_weak)
}

qqPlot(mean_sample_weak)
shapiro.test(mean_sample_weak)

```

The data is not normally distributed. The qqPlot of the "weak" column shows data points that are outside of the confidence interval. Additionally, the shapiro-wilk test returns a p-value less than 0.05, which means that we reject the null hypothesis of the data being normally distributed. The shapiro test for the "dominant" column returns the same trend — we must reject the null hypothesis that the dexterity data is normally distributed. 
However, by taking an increasing number of samples/sample sizes from the non-normal dataset and graphing the distribution of means we can approach a normal distribution. The shapiro test of a distribution of means returns a value greater than 0.05 and thus we cannot reject the null hypothesis that the data is normally distributed. 


#### Regardless of whether you think the assumptions of the t-test hold, report the 95% confidence interval for the mean difference using the following steps:

#### (d. 3pts) First, calculate this manually by finding the mean, sd, se, and t value

```{r}

# Replace NULL with appropriate code
dexterity$diff <- dexterity$Weak - dexterity$Dominant

y_bar=mean(dexterity$diff)
s=sd(dexterity$diff)
se=s/sqrt(length(dexterity$diff))

t_star= qt(1-0.025, length(dexterity$diff)-1)

```

My mean is `10.07` and SE = `0.818`. The critical t value is `2.0345`.


#### (e. 2pts) Now calculate and report the interval:
```{r}

# Replace NULL with appropriate code

lower= y_bar - (t_star*se)
upper= y_bar + (t_star*se)

```
The 95% confidence interval for the mean difference in dexterity [INDICATE LEFT-RIGHT or RIGHT-LEFT] is [`r lower`,`r upper`].

#### (f. 2pts) Find the 95% CI using the t.test function in R. Does it match your results?

```{r}

# Test code here
CI <- t.test(dexterity$diff)

```

[Your answer here]

#### (g. 3pts) Use the 95% CI to reject or fail to reject your null hypothesis. State your conclusions about the dominant v. weak hand dexterity.


[Your answer here]


### Q3: Natural selection in birds  (30 pts)
  
In 1898, Hermon Bumpus collected data on one of the first examples of natural selection directly observed in nature. Immediately following a bad winter storm, 136 English house sparrows were collected and brought indoors. Of these, 72 subsequently recovered, but 64 died :(. Bumpus made several measurements on all of the birds, and he was able to demonstrate strong natural selection on some of the traits as a result of this storm.  

Bumpus published all of his data, and you can find them in the file *bumpus.csv*. In this problem, you will test whether the birds that survived or died (survival) differed in *total length* (total_length_mm).  
  
#### (a. 2pts) Clearly state your null and alternative hypotheses of your two-sample t-test.  

[Your answer here]

#### (b. 5pts) Visualize your data in some meaningful way, and explain what information you get from the visualization. 

```{r}

# Import data here

# Plot code here

```

[Description here]

#### (c. 2pts) What is the appropriate test you should use to compare mean body length between dying and surviving birds? Write the null and alternative hypotheses.

[Your answer here]


#### (d. 3pts) Are the data normal? Include the Shapiro-Wilk p-value and the Q-Qplot and explain how this influences your choice of statistical test.

```{r}

# Normality assumption code here

```
[Your answer here]


#### (e. 3pts) Compare the F (var.test) and levene tests (in the car package) for testing unequal variances. Which one should you use for these data?

```{r}

# var.test and leveneTest here

```

[Your answer here]

#### (f. 2pts) Conduct the appropriate t-test and state your conclusions in terms of the null hypothesis.

```{r}

# T-test code here

```
[Your answer here]

#### (e. 10pts) Conduct your own statistical test on any other measurement in the dataset. Visualize the data, state your hypotheses, check assumptions, conduct your test, and report results. 

```{r}

# Plot code here

```
[Hypotheses here]

```{r}

# Assumption checks here


```
[Assumption discussion here]

```{r}

# Test code here

```
[Interpretation here]

  
### Q4: Robustness of the t-test (30pts)
  
The t-test is fairly robust to its assumptions. This means that even when the assumptions are not correct, the t-test often performs quite well. Remember that the two-sample t-test has the following assumptions:

** The variables have a normal distribution in the populations

** The variance of those distributions is the same in the two populations

** The two samples are random samples.  
  

To get started on this exercise, open the script *robustness.R*. It should pop up in another tab in your R Studio console. This script allows you to test how robust the results of t-test are to data that violate the assumptions. First, specify what the true distributions look like. You can do this by altering the code in the top few lines of the script. 

To start, run all the code in the script using *Run > Run all*. Two things should happen: 

(1) you should see a plot pop up that shows you the shape of your two distributions, and 

(2) R will output either your type I error if your true means are the same or your type II error if your true means are different. You should see something like:  
  
[1] "Your true TYPE I ERROR RATE is: 0.0498"  
  
This value should be close to 0.05 when the assumptions are met, which is our pre-set type I error $(\alpha = 0.05)$.  


Here is what just happened: R just artificially created 5,000 samples of 5 individuals each from both populations, and ran 5000 t-tests comparing the means. It tallied the number of significant and non-significant t-tests. In this case, both distributions are normal and the variances are equal, just as assumed by the t-test. We expect the t-test to work quite well in this case.  

Take a moment to think about what "working well" means. If the null hypothesis is true, then the Type 1 error rate given by the simulation should be close to our stated Type I error rate, $\alpha$. *Remember that Type I error is falsely rejecting a true null hypothesis*. An inflated Type I error rate means that we falsely reject the null hypothesis more than our pre-specified rate $\alpha$. 

Answer the following questions as you explore the effect of distribution shape and sample size on your Type I error. You do NOT need to include any of the code from the script.
  
#### (a. 5pts) *Unequal standard deviation, equal sample size*.
Make the standard deviations of the two populations unequal (all other parameters equal). What happens to the Type I error? Explore multiple combinations of standard deviations. What do you notice?

[Your answer here]

#### (b. 5pts) *Unequal standard deviation, unequal sample size*.
Keep the standard devations unequal and increase the sample size of one of the populations. Now exchange sample size 1 and sample size 2. What do you notice?

[Your answer here]

#### (c. 5pts) *Skew, equal sample size*.
Set the standard deviations of both populations to 1, the means of both populations to 4, and the sample size of both populations to 5. Change the skew of the second population to true (SKEWED2 = TRUE). 

[Your answer here]

##### What is your type I error rate?

[Your answer here]

##### What is the effect of changing the mean for both populations (still keeping them equal)?

[Your answer here]

##### What is the effect of increasing the sample size for the normal sample? What about the skewed sample? 

[Your answer here]


##### Play around with the sample sizes. Approximately how many samples are needed to attain a Type I error rate close to 0.05? (assume equal sample sizes)

[Your answer here]

#### (d. 5pts) Set the sample size = 25 for both populations, keeping means equal. Try two or three combinations that you think will give you an inflated Type I Error Rate. Do you think that the t-test is robust to violations of its assumptions if your sample size is large enough? Explain why or why not based on the value of your type I error rates.

[Your answer here]


#### (e. 5pts) Now set your sample means to be different from each other. Set sample 1 mean = 20 and sample 2 mean = 15. Assuming that SD for both samples is 3, how many samples are needed to get a type II error = 0.2?

[Your answer here]


#### (f. 2pts) What does this tell you about the power of your test?


[Your answer here]


#### (g. 3pts) Finally, keep the same parameters as in part E, but set the population with mean=15 to be skewed. What happened to your type II error? About how many samples are needed for each group (assume equal sample sizes) to reduce it to 0.2?

[Your answer here]



